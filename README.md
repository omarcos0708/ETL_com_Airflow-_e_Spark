# ETL_com_Airflow-_e_Spark

Objetivo: a atividade prática tem como objetivo proporcionar aos alunos a experiência de implementar um projeto ETL (Extração, Transformação e Carregamento), utilizando o Apache Airflow para orquestrar o processo e o Apache Spark para a manipulação dos dados. Os alunos irão trabalhar com dados de vendas, aplicando conceitos de cargas full e incrementais, e desenvolvendo habilidades práticas essenciais para o Desenvolvimento em Cloud Aplicada.

Materiais e Ferramentas:

●   PostgreSQL com dados de vendas pré-carregados.

●   Apache Spark para processamento de dados.

●   Apache Airflow para orquestração de pipelines.

●   Hadoop HDFS para armazenamento de dados.

●    Ambiente de desenvolvimento integrado (IDE) ou Jupyter Notebook.

